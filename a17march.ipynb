{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1237e0c-a343-4bbc-8a1a-7af4ad7007bc",
   "metadata": {},
   "source": [
    "# Quetion : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b191a4-6a7e-48f7-bef4-9d0b05ca9f1e",
   "metadata": {},
   "source": [
    "Missing values in a dataset refer to the absence of data for a particular observation or feature. This can happen due to a variety of reasons, such as data collection errors, survey non-response, or measurement equipment failure.\n",
    "\n",
    "It is essential to handle missing values before performing any analysis or modeling because they can cause bias in the results, lead to inaccurate predictions, and affect the generalizability of the model. Ignoring missing values or dropping rows with missing values can also lead to a loss of valuable information and reduce the representativeness of the dataset.\n",
    "\n",
    "Some algorithms that are not affected by missing values include tree-based methods such as decision trees, random forests, and gradient boosting machines. These algorithms can handle missing values by either excluding the missing values or splitting the data based on whether the feature is missing or not. Other algorithms that can handle missing values include k-nearest neighbors (KNN) and probabilistic matrix factorization. In addition, some algorithms, such as support vector machines (SVMs), can handle missing values by imputing them with some predefined value. However, imputing missing values with a single value can lead to biased results, and it is often better to use more sophisticated imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2633f0-3c2e-40ae-9128-d2969f0f86e4",
   "metadata": {},
   "source": [
    "# Quetion : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c87bf-bbae-4c0e-bfb8-735ba1bd508e",
   "metadata": {},
   "source": [
    "Drop missing values: In this technique, we remove any rows or columns that contain missing values. This method is used when we have a large dataset and the percentage of missing values is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467dbe61-6625-4cda-8058-c2273e0c6e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "3  4.0  8.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4],\n",
    "                   'B': [5, None, 7, 8]})\n",
    "df_drop = df.dropna()\n",
    "\n",
    "df_drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04385e-e4e2-4486-82b6-72aeb8fdcda0",
   "metadata": {},
   "source": [
    "Mean/median imputation: In this technique, we replace missing values with the mean or median of the column. This method is used when the number of missing values is small compared to the total number of rows.\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a429ce6c-6439-4a0c-9e7b-6724c70e0429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "0  1.000000  5.000000\n",
       "1  2.000000  6.666667\n",
       "2  2.333333  7.000000\n",
       "3  4.000000  8.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4],\n",
    "                   'B': [5, None, 7, 8]})\n",
    "df_mean = df.fillna(df.mean())\n",
    "\n",
    "df_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6f86a-7727-46c7-8fea-596510377c8a",
   "metadata": {},
   "source": [
    "Forward/backward filling: In this technique, we replace missing values with the previous or next valid value in the column. This method is used when the missing values occur in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993454c0-ac24-4649-b9ae-86cf8ccccf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "1  2.0  5.0\n",
       "2  2.0  5.0\n",
       "3  2.0  8.0\n",
       "4  5.0  9.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2, None, None, 5],\n",
    "                   'B': [5, None, None, 8, 9]})\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "df_ffill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087a315-5a33-4576-a205-6830484bca7b",
   "metadata": {},
   "source": [
    "Interpolation: In this technique, we replace missing values with values that lie between the existing values in the column. This method is used when the missing values occur in a sequence and we want to fill the values with the most probable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f922eb92-25b3-46ba-a6d1-f9852612990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "1  2.0  6.0\n",
       "2  3.0  7.0\n",
       "3  4.0  8.0\n",
       "4  5.0  9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2, None, None, 5],\n",
    "                   'B': [5, None, None, 8, 9]})\n",
    "df_interpolate = df.interpolate()\n",
    "df_interpolate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65b328-bdec-4182-b8b1-2c9ddd8dc3f6",
   "metadata": {},
   "source": [
    "# Quetion : 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597115e-dd32-4d0e-b188-abeefdd499b0",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where the number of samples in each class of a classification problem is not equal, resulting in a skewed distribution of class labels. For instance, in a binary classification problem, if the number of samples in one class is significantly higher than the other, the data is said to be imbalanced.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to biased model performance and inaccurate predictions. In such cases, the model may become overfit to the majority class and fail to identify the minority class, leading to low precision and recall scores. This can have severe consequences in real-world applications, such as medical diagnosis, fraud detection, or credit risk assessment, where identifying the minority class is of utmost importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbe95c-20e2-42cf-bc72-26bf2dc2635c",
   "metadata": {},
   "source": [
    "# Quetion : 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db2af4-76c3-4337-9c31-727c254205c3",
   "metadata": {},
   "source": [
    "Up-sampling and down-sampling are two commonly used techniques for handling imbalanced data in a classification problem.\n",
    "\n",
    "Upsampling involves increasing the number of instances in the minority class by randomly replicating them, resulting in a more balanced dataset. This technique is useful when the minority class has very few instances compared to the majority class.\n",
    "\n",
    "Downsampling involves reducing the number of instances in the majority class by randomly selecting a subset of them, resulting in a more balanced dataset. This technique is useful when the majority class has a significantly larger number of instances compared to the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e7c4c-b94b-4f96-917a-ca5b6f3de7df",
   "metadata": {},
   "source": [
    "# Quetion : 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802e8d9-f9d8-423c-9f04-3fb20c2735ec",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used in machine learning to artificially increase the size of a dataset by creating additional synthetic data samples. The goal of data augmentation is to enhance the diversity of the training data and help prevent overfitting of the machine learning model.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation technique used to address the problem of imbalanced datasets. It works by creating synthetic samples of the minority class by interpolating between neighboring instances. This helps to balance the class distribution, improve model performance on the minority class, and prevent overfitting to the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a5b05-5317-4c65-b64b-a305411913ca",
   "metadata": {},
   "source": [
    "# Quetion : 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d527c8-57b0-4645-b0dc-a2ad7dc9dcb5",
   "metadata": {},
   "source": [
    "Outliers are data points that significantly differ from other data points in a dataset. Outliers can be caused by various factors, such as measurement errors, data entry errors, or extreme values in the data. Outliers can have a significant impact on statistical analysis and machine learning models, as they can skew the results and lead to incorrect conclusions.\n",
    "\n",
    "Handling outliers is essential for the following reasons:\n",
    "\n",
    "Accurate statistical analysis: Outliers can distort the results of statistical analysis and lead to incorrect conclusions. Removing outliers can help to ensure that statistical analysis is accurate and reliable.\n",
    "\n",
    "Better machine learning models: Outliers can negatively impact the performance of machine learning models, as they can cause the model to overfit to the noise in the data. Handling outliers can help to ensure that machine learning models are more accurate and generalize better to new data.\n",
    "\n",
    "Improved data visualization: Outliers can also make it difficult to visualize and interpret data. Handling outliers can help to create more informative and accurate data visualizations that better represent the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f8c7e-d74b-4c1e-b77b-d51f0e5bba79",
   "metadata": {},
   "source": [
    "# Quetion : 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e588978-5902-41c1-8d43-767f5f7748bf",
   "metadata": {},
   "source": [
    "\n",
    "Handling missing data is an essential step in data analysis, as missing data can lead to biased results and affect the accuracy of the analysis. Here are some techniques that can be used to handle missing data:\n",
    "\n",
    "Deleting missing data: One way to handle missing data is to simply remove the rows or columns with missing data. This technique is straightforward, but it can lead to loss of information and may not be feasible if there is a significant amount of missing data.\n",
    "\n",
    "Imputation: Imputation involves replacing missing data with estimated values. There are several methods for imputation, including mean imputation, median imputation, and regression imputation. Mean imputation involves replacing missing values with the mean of the available data, while median imputation involves replacing missing values with the median. Regression imputation involves using a regression model to predict the missing values based on other variables in the dataset.\n",
    "\n",
    "Multiple imputation: Multiple imputation involves creating multiple imputed datasets by generating plausible values for the missing data based on the observed data. The results from the multiple datasets are then combined to provide more accurate estimates.\n",
    "\n",
    "Model-based imputation: Model-based imputation involves using a statistical model to estimate missing values based on the available data. This technique is useful for handling missing data in complex datasets with many variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f3bef-cc6c-4811-9859-fcfcec1e398e",
   "metadata": {},
   "source": [
    "# Quetion : 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651fa79-5ee8-42f0-b09e-4b382a7851b9",
   "metadata": {},
   "source": [
    "When working with a large dataset with missing data, it is essential to determine whether the missing data is missing at random or if there is a pattern to the missing data. Here are some strategies to determine the missing data pattern:\n",
    "\n",
    "Visualizing missing data: One way to determine the pattern of missing data is to visualize it using plots such as a heatmap or a missing data matrix. These plots can help to identify the variables with missing data and whether the missing data is distributed randomly or not.\n",
    "\n",
    "Descriptive statistics: Another strategy to determine the pattern of missing data is to compute descriptive statistics, such as mean, median, or mode, for the variables with missing data and compare them to the statistics for the variables without missing data. If the statistics for the variables with missing data are significantly different from those without missing data, it may indicate that the missing data is not random.\n",
    "\n",
    "Hypothesis testing: Hypothesis testing can be used to determine if there is a significant difference between the data with missing values and the data without missing values. This technique can be used to identify if there is a pattern to the missing data.\n",
    "\n",
    "Machine learning algorithms: Machine learning algorithms, such as decision trees, can be used to identify the variables that are most important in predicting the missing data. If the variables with missing data are not important predictors, it may indicate that the missing data is not related to the variables' values.\n",
    "\n",
    "Correlation analysis: Correlation analysis can be used to determine the relationship between the variables with missing data and the other variables in the dataset. If the missing data is correlated with certain variables, it may indicate that the missing data is not random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b2244-547f-460d-815d-b47cbeb87498",
   "metadata": {},
   "source": [
    "# Quetion : 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be3025-3c4e-4db4-b072-9647493ac0e4",
   "metadata": {},
   "source": [
    "evaluating the performance of a machine learning model on an imbalanced dataset requires careful consideration of the specific characteristics of the dataset and the goals of the analysis. A combination of performance metrics and techniques such as resampling and ensemble techniques can be used to address the challenges posed by imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c381b2-8c87-4153-8bb5-e5f99f89364b",
   "metadata": {},
   "source": [
    "# Quetion : 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3b34c-86d4-4674-bbf0-ac503898c49f",
   "metadata": {},
   "source": [
    "When dealing with an unbalanced dataset, one common approach is to balance the dataset by either oversampling the minority class or down-sampling the majority class. Here are some methods to down-sample the majority class:\n",
    "\n",
    "Random under-sampling: In random under-sampling, we randomly select a subset of the majority class examples to match the number of examples in the minority class. This can be done using various techniques such as stratified sampling or random sampling.\n",
    "\n",
    "Cluster centroids: In cluster centroids, we identify clusters of the majority class and replace the centroid of each cluster with the cluster's centroid. This method can help to preserve the information in the majority class while reducing its size.\n",
    "\n",
    "Tomek links: Tomek links are pairs of examples from different classes that are close to each other. We can remove the examples from the majority class that form Tomek links to the minority class. This method can help to improve the decision boundary between the two classes.\n",
    "\n",
    "NearMiss: NearMiss is an under-sampling method that selects examples from the majority class that are closest to the minority class examples. This method can help to retain the structure of the majority class while reducing its size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e238b-aa67-4e4f-8f4c-0f26501eb404",
   "metadata": {},
   "source": [
    "# Quetion : 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa627b-3332-4de4-ac33-fa0258f927dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
